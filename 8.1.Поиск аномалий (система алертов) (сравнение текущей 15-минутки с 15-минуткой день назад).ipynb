{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2830b27a",
   "metadata": {},
   "source": [
    "### 8. Поиск аномалий (система алертов)\n",
    "##### Задача: напишите систему алертов для нашего приложения\n",
    "Система должна с периодичностьç каждые 15 минут проверять ключевые метрики, такие как активные пользователи в ленте / мессенджере, просмотры, лайки, CTR, количество отправленных сообщений. \n",
    "1. Изучите поведение метрик и подберите наиболее подходящий метод для детектирования аномалий. \n",
    "Проверяю отклонение значения метрики в текущую 15-минутку от значения в такую же 15-минутку день назад. \n",
    "2. В случае обнаружения аномального значения, в чат должен отправиться алерт - сообщение со следующей информацией: метрика, ее значение, величина отклонения. В сообщение можно добавить дополнительную информацию, которая поможет при исследовании причин возникновения аномалии, это может быть, например,  график, ссылки на дашборд/чарт в BI системе. \n",
    "3. Автоматизируйте систему алертов с помощью Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007da48b",
   "metadata": {},
   "source": [
    "#### Сравниваню интересующее значение ключевой метрики за 15-минутку со значением в это же время сутки назад."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ee59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # для нахождения даты \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import telegram\n",
    "import pandahouse as ph\n",
    "from datetime import date, datetime, timedelta\n",
    "import io # сохраняю картинки в буфере\n",
    "\n",
    "#скрыть токен и chat_id, когда выложу в гите\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "from airflow.decorators import dag, task\n",
    "#from airflow.operators.python import get_current_contex\n",
    "\n",
    "\n",
    "#для подключения к clickhouse\n",
    "connection = {\n",
    "              'host':'https://clickhouse.lab.karpov.courses',\n",
    "              'database':'simulator_20221020',\n",
    "              'user':'student', \n",
    "              'password':'dpo_python_2020'\n",
    "             }\n",
    "\n",
    "\n",
    "# Дефолтные параметры, которые прокидываются в таски\n",
    "default_args = {\n",
    "                'owner': 'aksakal',\n",
    "                'depends_on_past': False,\n",
    "                'retries': 2,\n",
    "                'retry_delay': timedelta(minutes=5),\n",
    "    \n",
    "                'email': 'bailukova.bk@gmail.com', # Почта для уведомлений\n",
    "                'email_on_failure': 'bailukova.bk@gmail.com', # Почта для уведомлений при ошибке\n",
    "                'email_on_retry': 'bailukova.bk@gmail.com', # Почта для уведомлений при перезапуске\n",
    "    \n",
    "                'start_date': datetime(2022, 11, 9), # старт дата, с которой собираем данные9/11/2022\n",
    "                }\n",
    "\n",
    "# Интервал запуска DAG\n",
    "schedule_interval = '*/15 * * * *'\n",
    "\n",
    "\n",
    "#функция поиска аномалиий c помощью алгоритма  аномалий в данных (межквартильный размах)\n",
    "def check_anomaly(data, metric, threshold=0.5):\n",
    "    # функция check_anomaly предлагает алгоритм проверки значения на аномальность посредством\n",
    "    # сравнения интересующего значения со значением в это же время сутки назад\n",
    "    # при желании алгоритм внутри этой функции можно изменить\n",
    "    current_ts = df['ts'].max()  # достаем максимальную 15-минутку из датафрейма - ту, которую будем проверять на аномальность\n",
    "    \n",
    "    if metric == 'users_message':\n",
    "        day_ago_ts = current_ts - pd.DateOffset(days=3)  # достаем такую же 15-минутку сутки назад\n",
    "    else:\n",
    "        day_ago_ts = current_ts - pd.DateOffset(days=1)  # достаем такую же 15-минутку сутки назад\n",
    "\n",
    "\n",
    "    current_value = df[df['ts'] == current_ts][metric].iloc[0] # достаем из датафрейма значение метрики в максимальную 15-минутку\n",
    "    day_ago_value = df[df['ts'] == day_ago_ts][metric].iloc[0] # достаем из датафрейма значение метрики в такую же 15-минутку сутки назад\n",
    "\n",
    "    # вычисляем отклонение\n",
    "    if current_value <= day_ago_value:\n",
    "        diff = abs(current_value / day_ago_value - 1)\n",
    "    else:\n",
    "        diff = abs(day_ago_value / current_value - 1)\n",
    "\n",
    "    # проверяем больше ли отклонение метрики заданного порога threshold\n",
    "    # если отклонение больше, то вернем 1, в противном случае 0\n",
    "    if diff > threshold:\n",
    "        is_alert = 1\n",
    "    else:\n",
    "        is_alert = 0 \n",
    "\n",
    "    return is_alert, current_value, diff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@dag(default_args=default_args, schedule_interval=schedule_interval, catchup=False)\n",
    "def aksakal_alert_less():\n",
    "\n",
    "    today = np.datetime64('today')\n",
    "\n",
    "    # считаю средние показатели метрик за 7 дней до сегодня + ставлю дату за вчера\n",
    "    @task\n",
    "    def extract_feed_7day():\n",
    "        query = ''' SELECT \n",
    "                              hm \n",
    "                            , avg(users_feed) as users_feed\n",
    "                            , avg(views) as views\n",
    "                            , avg(likes) as likes\n",
    "                            , avg(ctr) as ctr\n",
    "                            , date\n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                              formatDateTime(toStartOfFifteenMinutes(time), '%R') as hm\n",
    "                            , uniqExact(user_id) as users_feed\n",
    "                            , countIf(user_id, action = 'view') as views\n",
    "                            , countIf(user_id, action = 'like') as likes\n",
    "                            , likes/views as ctr\n",
    "                            , today()-1 as date\n",
    "                        FROM \n",
    "                            {db}.feed_actions\n",
    "                        WHERE \n",
    "                            time >=  today() - 7 and time < today()\n",
    "\n",
    "                        GROUP BY  date, hm\n",
    "                        ORDER BY date, hm)\n",
    "\n",
    "                    GROUP BY  date, hm\n",
    "                    ORDER BY date, hm\n",
    "                    '''\n",
    "        df_cube_feed_7day = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_feed_7day\n",
    "\n",
    "\n",
    "    # считаю метрики только за сегодня\n",
    "    @task\n",
    "    def extract_feed_today():\n",
    "        query = ''' SELECT\n",
    "                          toStartOfFifteenMinutes(time) as ts\n",
    "                        , toDate(time) as date\n",
    "                        , formatDateTime(ts, '%R') as hm\n",
    "                        , uniqExact(user_id) as users_feed\n",
    "                        , countIf(user_id, action = 'view') as views\n",
    "                        , countIf(user_id, action = 'like') as likes\n",
    "                        , likes/views as ctr\n",
    "\n",
    "                    FROM \n",
    "                        {db}.feed_actions\n",
    "                    WHERE \n",
    "                        time >= today() and time < toStartOfFifteenMinutes(now())\n",
    "\n",
    "                    GROUP BY date, hm, ts\n",
    "                    ORDER BY date, hm \n",
    "                    '''\n",
    "        df_cube_feed_today = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_feed_today\n",
    "\n",
    "\n",
    "    # WHERE time >=  today() and time < toStartOfFifteenMinutes(now()) - беру период за вчера до сегодня без текущих 15 минут,\n",
    "    # тк текущая 15-минутка может быть неполная и тогда получу алерт, что данные упали, хотя это не так\n",
    "    # toStartOfFifteenMinutes(now()) - округляет текущее время до начала текущей 15 минутки \n",
    "    # formatDateTime(time, '%R') as hm  - округленное до 15 минуток время выводит в формате часы-минуты \n",
    "    # добавила колонки date, hm - для удобства построения графиков \n",
    "\n",
    "\n",
    "    # считаю метрики за 3 дня до сегодня + сегодня для users_message, тк там есть закономерность каждые 3 дня\n",
    "    @task\n",
    "    def extract_users_message():\n",
    "        query = ''' SELECT \n",
    "                            ts, date, hm, users_message\n",
    "                    FROM\n",
    "\n",
    "                        (SELECT\n",
    "                              toStartOfFifteenMinutes(time) as ts\n",
    "                            , toDate(time) as date\n",
    "                            , formatDateTime(ts, '%R') as hm\n",
    "                            , uniqExact(user_id) as users_message\n",
    "\n",
    "                        FROM \n",
    "                          {db}.message_actions\n",
    "                        WHERE \n",
    "                           time >= today() and time < toStartOfFifteenMinutes(now())\n",
    "\n",
    "                        GROUP BY date, hm, ts\n",
    "                        ORDER BY date)\n",
    "\n",
    "                        UNION ALL               \n",
    "\n",
    "                       (SELECT\n",
    "                              toStartOfFifteenMinutes(time) as ts\n",
    "                            , toDate(time) as date\n",
    "                            , formatDateTime(ts, '%R') as hm\n",
    "                            , uniqExact(user_id) as users_message\n",
    "\n",
    "                        FROM \n",
    "                          {db}.message_actions\n",
    "                        WHERE \n",
    "                            time >= today()-3 and time < today()-2\n",
    "\n",
    "                        GROUP BY date, hm, ts\n",
    "                        ORDER BY date)\n",
    "                    '''\n",
    "        df_cube_users_message = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_users_message\n",
    "\n",
    "\n",
    "    # считаю средние показатели метрик за 10 дней до сегодня + ставлю дату за вчера\n",
    "    # буду смотреть аномалии по алгоритму для метрик feed \n",
    "    @task\n",
    "    def extract_sent_message():\n",
    "        query = ''' \n",
    "                SELECT \n",
    "                              hm\n",
    "                            , date\n",
    "                            , avg(sent_message) as sent_message\n",
    "                FROM\n",
    "\n",
    "                    (SELECT\n",
    "                          today()-1 as date\n",
    "                        , formatDateTime(toStartOfFifteenMinutes(time), '%R') as hm\n",
    "                        , count(user_id) as sent_message\n",
    "\n",
    "                    FROM \n",
    "                       {db}.message_actions\n",
    "                    WHERE \n",
    "                        time >=  today()-7 and time < today()\n",
    "\n",
    "                    GROUP BY date, hm\n",
    "                    ORDER BY date, hm)  \n",
    "\n",
    "                GROUP BY date, hm\n",
    "                ORDER BY date, hm      \n",
    "                    '''\n",
    "        df_cube_sent_message = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_sent_message\n",
    "\n",
    "\n",
    "\n",
    "    @task\n",
    "    def extract_sent_message_today():\n",
    "        query = ''' \n",
    "                SELECT \n",
    "                          toStartOfFifteenMinutes(time) as ts\n",
    "                        , toDate(time) as date\n",
    "                        , formatDateTime(ts, '%R') as hm\n",
    "                        , count(user_id) as sent_message\n",
    "\n",
    "                    FROM \n",
    "                        {db}.message_actions\n",
    "                    WHERE \n",
    "                        time >= today() and time < toStartOfFifteenMinutes(now())\n",
    "\n",
    "                    GROUP BY date, hm, ts\n",
    "                    ORDER BY date, hm \n",
    "                    '''\n",
    "        df_cube_sent_message_today = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_sent_message_today\n",
    "\n",
    "\n",
    "    #объединяю данные из 2 датафреймов в 1 для выявления аномалий в метриках\n",
    "    @task\n",
    "    def transform_data_feed(df_cube_feed_7day, df_cube_feed_today):\n",
    "\n",
    "        df_cube_feed_7day['ts'] = df_cube_feed_7day['date'].astype ( str )+' '+df_cube_feed_7day['hm']\n",
    "        df_cube_feed_7day['ts'] = pd.to_datetime(df_cube_feed_7day['ts'], format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "        data_feed = pd.concat([df_cube_feed_7day, df_cube_feed_today], ignore_index=True)\n",
    "        data_feed = data_feed.fillna(0)   # заменяю пропущенные значения NaN на 0  \n",
    "        \n",
    "        return data_feed\n",
    "\n",
    "    @task\n",
    "    def create_data_feed_dau(data_feed): \n",
    "        data_feed_dau = data_feed[['hm', 'date', 'ts', 'users_feed']].copy()\n",
    "        return data_feed_dau\n",
    "        \n",
    "    @task\n",
    "    def create_data_feed_views(data_feed): \n",
    "        data_feed_views = data_feed[['hm', 'date', 'ts', 'views']].copy()\n",
    "        return data_feed_views\n",
    "\n",
    "    @task\n",
    "    def create_data_feed_likes(data_feed): \n",
    "        data_feed_likes = data_feed[['hm', 'date', 'ts', 'likes']].copy()\n",
    "        return data_feed_likes\n",
    "\n",
    "    @task\n",
    "    def create_data_feed_ctr(data_feed): \n",
    "        data_feed_ctr =  data_feed[['hm', 'date', 'ts', 'ctr']].copy()\n",
    "        return data_feed_ctr    \n",
    "\n",
    "\n",
    "    #объединяю данные из 2 датафреймов в 1 для выявления аномалий в метриках\n",
    "    @task\n",
    "    def transform_data_sent_message(df_cube_sent_message, df_cube_sent_message_today):\n",
    "\n",
    "        df_cube_sent_message['ts'] = df_cube_sent_message['date'].astype ( str )+' '+ df_cube_sent_message['hm']\n",
    "        df_cube_sent_message['ts'] = pd.to_datetime(df_cube_sent_message['ts'], format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "        data_sent_message = pd.concat([df_cube_sent_message, df_cube_sent_message_today], ignore_index=True)\n",
    "\n",
    "        return data_sent_message\n",
    "\n",
    "\n",
    "    @task\n",
    "    def run_alerts(df_1, metrics):\n",
    "        data = df_1\n",
    "        metric = metrics\n",
    "\n",
    "\n",
    "        # данные для подключения к боту\n",
    "        my_token = 'token' # заменила настоящий токен, поскольку репозиторий публичный\n",
    "        bot = telegram.Bot(token=my_token) # получаю доступ к бот\n",
    "        chat_id = id_number # заменила настоящий id, поскольку репозиторий публичный\n",
    "\n",
    "        \n",
    "        # проверяем метрику на аномальность алгоритмом, описаным внутри функции check_anomaly()\n",
    "\n",
    "        is_alert, current_value, diff = check_anomaly(data, metric, threshold=0.5) \n",
    "    \n",
    "        if is_alert == 1:\n",
    "            msg = '''Метрика {metric}:\\nтекущее значение = {current_value:.2f}\\nотклонение от вчера {diff:.2%}'''.format(metric=metric, current_value=current_value, diff=diff)\n",
    "\n",
    "            sns.set(rc={'figure.figsize': (16, 10)}) # задаем размер графика\n",
    "            plt.tight_layout()\n",
    "\n",
    "            ax = sns.lineplot( # строим линейный график\n",
    "                data = data.sort_values(by=['date', 'hm']), # задаем датафрейм для графика\n",
    "                x=\"hm\", y=metric, # указываем названия колонок в датафрейме для x и y\n",
    "                hue=\"date\" # задаем \"группировку\" на графике, т е хотим чтобы для каждого значения date была своя линия построена\n",
    "                )\n",
    "\n",
    "            for ind, label in enumerate(ax.get_xticklabels()): # этот цикл нужен чтобы разрядить подписи координат по оси Х,\n",
    "                if ind % 5 == 0:\n",
    "                    label.set_visible(True)\n",
    "                else:\n",
    "                    label.set_visible(False)\n",
    "            ax.set(xlabel='time') # задаем имя оси Х\n",
    "            ax.set(ylabel=metric) # задаем имя оси У\n",
    "\n",
    "            ax.set_title('{}'.format(metric)) # задае заголовок графика\n",
    "            ax.set(ylim=(0, None)) # задаем лимит для оси У\n",
    "\n",
    "            # формируем файловый объект\n",
    "            plot_object = io.BytesIO()\n",
    "            ax.figure.savefig(plot_object)\n",
    "            plot_object.seek(0)\n",
    "            plot_object.name = '{0}.png'.format(metric)\n",
    "            \n",
    "            print(msg)\n",
    "            plt.show()\n",
    "            \n",
    "            plt.close()\n",
    "\n",
    "            # отправляем алерт\n",
    "            bot.sendMessage(chat_id=chat_id, text=msg)\n",
    "            bot.sendPhoto(chat_id=chat_id, photo=plot_object)\n",
    "        return\n",
    "        \n",
    "    \n",
    "    #вызов всех функций\n",
    "    df_cube_feed_7day = extract_feed_7day()\n",
    "    df_cube_feed_today = extract_feed_today()\n",
    "    df_cube_users_message = extract_users_message()\n",
    "    df_cube_sent_message = extract_sent_message()\n",
    "    df_cube_sent_message_today = extract_sent_message_today()\n",
    "\n",
    "    data_feed =  transform_data_feed(df_cube_feed_7day, df_cube_feed_today) \n",
    "\n",
    "    data_feed_dau = create_data_feed_dau(data_feed)\n",
    "    data_feed_views = create_data_feed_views(data_feed)\n",
    "    data_feed_likes = create_data_feed_likes(data_feed)\n",
    "    data_feed_ctr = create_data_feed_ctr(data_feed)\n",
    "    data_sent_message = transform_data_sent_message(df_cube_sent_message, df_cube_sent_message_today)\n",
    "\n",
    "    run_alerts(df_1 = df_cube_users_message, metrics = 'users_message')\n",
    "    run_alerts(df_1 = data_feed_dau, metrics = 'users_feed')\n",
    "    run_alerts(df_1 = data_feed_views, metrics = 'views')\n",
    "    run_alerts(df_1 = data_feed_likes, metrics = 'likes')\n",
    "    run_alerts(df_1 = data_feed_ctr, metrics = 'ctr')\n",
    "    run_alerts(df_1 = data_sent_message, metrics = 'sent_message')\n",
    "\n",
    "\n",
    "\n",
    "aksakal_alert_less = aksakal_alert_less()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
