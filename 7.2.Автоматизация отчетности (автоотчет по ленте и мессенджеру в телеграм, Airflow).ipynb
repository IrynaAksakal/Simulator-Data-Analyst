{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "626abb6f",
   "metadata": {},
   "source": [
    "### 7.2.Отчет по приложению\n",
    "##### Задача: соберите единый отчет по работе всего приложения. В отчете должна быть информация и по ленте новостей, и по сервису отправки сообщений. \n",
    "\n",
    "1. Продумайте, какие метрики необходимо отобразить в этом отчете? Как можно показать их динамику?  Приложите к отчету графики или файлы, чтобы сделать его более наглядным и информативным. Отчет должен быть не просто набором графиков или текста, а помогать отвечать бизнесу на вопросы о работе всего приложения совокупно. \n",
    "2. Автоматизируйте отправку отчета с помощью Airflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90272450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import pandahouse as ph\n",
    "\n",
    "import telegram\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from airflow.decorators import dag, task\n",
    "#from airflow.operators.python import get_current_contex\n",
    "\n",
    "\n",
    "#для подключения к clickhouse\n",
    "connection = {\n",
    "              'host':'https://clickhouse.lab.karpov.courses',\n",
    "              'database':'simulator_20221020',\n",
    "              'user':'student', \n",
    "              'password':'dpo_python_2020'\n",
    "             }\n",
    "\n",
    "\n",
    "# Дефолтные параметры, которые прокидываются в таски\n",
    "default_args = {\n",
    "                'owner': 'aksakal',\n",
    "                'depends_on_past': False,\n",
    "                'retries': 2,\n",
    "                'retry_delay': timedelta(minutes=5),\n",
    "                'start_date': datetime(2022, 11, 14), # старт дата, с которой собираем данные 14/11/2022\n",
    "                }\n",
    "\n",
    "# Интервал запуска DAG\n",
    "schedule_interval = '0 11 * * *' #запускаем даг каждый день в 11 часов\n",
    "\n",
    "\n",
    "@dag(default_args=default_args, schedule_interval=schedule_interval, catchup=False)\n",
    "def aksakal_my_bot_112022():\n",
    "\n",
    "    # данные для подключения к боту\n",
    "    my_token = 'token' # заменила настоящий токен, поскольку репозиторий публичный\n",
    "    bot = telegram.Bot(token=my_token) # получаю доступ к бот\n",
    "    chat_id = id_number # заменила настоящий id, поскольку репозиторий публичный\n",
    "\n",
    "\n",
    "\n",
    "    #выгружаю данные из базы feed за последние 14 дней и сразу рассчитываю метрики ПО SOURCE за предыдущий день\n",
    "    @task\n",
    "    def extract_feed():\n",
    "        query  = '''\n",
    "                    SELECT \n",
    "                       toDate(time) as event_date,\n",
    "                       dateName('weekday', toDate(time)) as week_day,\n",
    "                       count(distinct user_id) as dau_feed, \n",
    "                       sum(action = 'like') as likes, \n",
    "                       sum(action = 'view') as views, \n",
    "                       round((likes /views) * 100, 2) as ctr, \n",
    "                       toISOWeek(toDate(time)) as iso_week,\n",
    "                       today()- 1 as report_day,\n",
    "\n",
    "                       (CASE\n",
    "                       WHEN iso_week = toISOWeek(report_day) THEN 'this_week'\n",
    "                       WHEN toISOWeek(report_day)-  iso_week = 1 THEN 'last_week'\n",
    "                       WHEN toISOWeek(report_day)-  iso_week >= 2 THEN 'more then 2 week'\n",
    "                       ELSE 'other week'\n",
    "                       END) as status\n",
    "\n",
    "                    FROM \n",
    "                       {db}.feed_actions \n",
    "                   WHERE \n",
    "                       toDate(time) >= today() - 14 and toDate(time) <= today()\n",
    "                       and status in ('this_week', 'last_week')\n",
    "                   group by \n",
    "                       event_date, week_day, status, iso_week, report_day\n",
    "                  order by \n",
    "                      event_date \n",
    "                     '''\n",
    "        df_cube_feed = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_feed\n",
    "\n",
    "    #toISOWeek(toDate(time)) as iso_week - номер недели в году\n",
    "    #today()- 1 as report_day - отчетная дата, нужна для условия в CASE\n",
    "    # в CASE от номера недели, на которую приходится отчетная дата, отнимаю номер недели по другим датам\n",
    "    #WHERE toDate(time) >= today() - 14 and toDate(time) <= today() - беру по сегодня, иначе на графике, где только 1 точка не отображаются данные. \n",
    "    #Потом в датафрейме для текстового сообщения просто отняла данные за сегодняшний день, чтобы считать отчет за вчера\n",
    "\n",
    "\n",
    "    @task\n",
    "    def extract_feed_source():\n",
    "        query  = '''\n",
    "                    SELECT \n",
    "                       toDate(time) as event_date, \n",
    "                       dateName('weekday', toDate(time)) as week_day,\n",
    "                       source,\n",
    "                       count(distinct user_id) as dau_feed,\n",
    "                       toISOWeek(toDate(time)) as iso_week,\n",
    "                       today()- 1 as report_day,\n",
    "\n",
    "                       (CASE\n",
    "                       WHEN iso_week = toISOWeek(report_day) THEN 'this_week'\n",
    "                       WHEN toISOWeek(report_day)-  iso_week = 1 THEN 'last_week'\n",
    "                       WHEN toISOWeek(report_day)-  iso_week >= 2 THEN 'more then 2 week'\n",
    "                       ELSE 'other week'\n",
    "                       END) as status\n",
    "\n",
    "                    FROM \n",
    "                       {db}.feed_actions \n",
    "                   WHERE \n",
    "                       toDate(time) >= today() - 14 and toDate(time) <= today()\n",
    "                       and status in ('this_week', 'last_week')\n",
    "                   group by \n",
    "                       event_date, week_day, source, status, iso_week, report_day\n",
    "                  order by \n",
    "                      event_date \n",
    "                 '''\n",
    "\n",
    "        df_cube_feed_source = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_feed_source\n",
    "\n",
    "    #sent_message - количество отправленных за день сообщений\n",
    "    #dau_message - количество пользователей, отправивших за день сообщение, \n",
    "    #тех, кто получил не считаю, тк они, возможно, прочитали, но ничего не ответили - считаю, что не совершили активное действие\n",
    "\n",
    "\n",
    "    @task\n",
    "    def extract_message():\n",
    "        query  = '''SELECT \n",
    "                        toDate(time) as event_date,\n",
    "                        dateName('weekday', toDate(time)) as week_day,\n",
    "                        count(distinct user_id) as dau_message,\n",
    "                        count(user_id) as sent_message, \n",
    "                        toISOWeek(toDate(time)) as iso_week,\n",
    "                        today()- 1 as report_day,\n",
    "\n",
    "                        (CASE\n",
    "                        WHEN iso_week = toISOWeek(report_day) THEN 'this_week'\n",
    "                        WHEN toISOWeek(report_day)-  iso_week = 1 THEN 'last_week'\n",
    "                        WHEN toISOWeek(report_day)-  iso_week >= 2 THEN 'more then 2 week'\n",
    "                        ELSE 'other week'\n",
    "                        END) as status\n",
    "                   FROM \n",
    "                        {db}.message_actions \n",
    "                   WHERE  \n",
    "                       toDate(time) >= today() - 14 and toDate(time) <= today()\n",
    "                       and status in ('this_week', 'last_week')\n",
    "                    group \n",
    "                        by event_date, week_day, status, iso_week, report_day\n",
    "                    order by\n",
    "                        event_date\n",
    "                 '''\n",
    "        df_cube_message = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_message\n",
    "\n",
    "\n",
    "    @task\n",
    "    def extract_message_source():\n",
    "        query  = '''SELECT \n",
    "                        toDate(time) as event_date, \n",
    "                        dateName('weekday', toDate(time)) as week_day,\n",
    "                        source,\n",
    "                        count(distinct user_id) as dau_message,\n",
    "                        toISOWeek(toDate(time)) as iso_week,\n",
    "                        today()- 1 as report_day,\n",
    "\n",
    "                        (CASE\n",
    "                        WHEN iso_week = toISOWeek(report_day) THEN 'this_week'\n",
    "                        WHEN toISOWeek(report_day)-  iso_week = 1 THEN 'last_week'\n",
    "                        WHEN toISOWeek(report_day)-  iso_week >= 2 THEN 'more then 2 week'\n",
    "                        ELSE 'other week'\n",
    "                        END) as status\n",
    "\n",
    "                   FROM \n",
    "                        {db}.message_actions \n",
    "                   WHERE  \n",
    "                       toDate(time) >= today() - 14 and toDate(time) <= today()\n",
    "                       and status in ('this_week', 'last_week')\n",
    "                    group by \n",
    "                        event_date, week_day, source, status, iso_week, report_day\n",
    "                    order by \n",
    "                        event_date\n",
    "                 '''\n",
    "        df_cube_message_source = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_message_source\n",
    "\n",
    "\n",
    "    @task\n",
    "    def extract_feed_stickiness(): \n",
    "        query  = ''' \n",
    "                WITH \n",
    "                    (SELECT\n",
    "                        count(DISTINCT user_id) AS mau\n",
    "                    FROM \n",
    "                        {db}.feed_actions\n",
    "                    WHERE \n",
    "                        time >= date_add(DAY, -10, now())\n",
    "                    AND \n",
    "                        time < toDate(now()) ) as t1\n",
    "        \n",
    "                SELECT\n",
    "                      toDate(time) as event_date,\n",
    "                      count(DISTINCT user_id) as dau,\n",
    "                      round((dau / t1), 2) as stickiness\n",
    "                FROM \n",
    "                    {db}.feed_actions\n",
    "                WHERE \n",
    "                    time >= date_add(DAY, -10, now()) AND time < toDate(now())\n",
    "                GROUP BY \n",
    "                    toDate(time)\n",
    "            '''\n",
    "        df_cube_feed_stickiness = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_feed_stickiness\n",
    "\n",
    "    \n",
    "    @task\n",
    "    def extract_message_stickiness(): \n",
    "        query  = ''' \n",
    "               WITH \n",
    "                    (SELECT\n",
    "                        count(DISTINCT user_id) AS mau\n",
    "                    FROM \n",
    "                        {db}.message_actions\n",
    "                    WHERE \n",
    "                        time >= date_add(DAY, -10, now())\n",
    "                    AND \n",
    "                        time < toDate(now()) ) as t1\n",
    "        \n",
    "                SELECT\n",
    "                      toDate(time) as event_date,\n",
    "                      count(DISTINCT user_id) as dau,\n",
    "                      round((dau / t1), 2) as stickiness\n",
    "                FROM \n",
    "                        {db}.message_actions\n",
    "                WHERE \n",
    "                    time >= date_add(DAY, -10, now()) AND time < toDate(now())\n",
    "                GROUP BY \n",
    "                    toDate(time)\n",
    "                '''\n",
    "        df_cube_message_stickiness = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_message_stickiness    \n",
    "\n",
    "\n",
    "\n",
    "#--средние значения метрик за предыдущую неделю, не включая день, за который отчет\n",
    "#--беру неделю назад, тк наше приложение развивается и показатели меняются, средние за весь период меньше, чем сегодняшние\n",
    "#-- тк количество активных пользователей с каждым днем по чуть-чуть растет\n",
    "\n",
    "    @task()\n",
    "    def transform_feed_week_mean(df_cube_feed):\n",
    "        df_cube_feed_week_mean = df_cube_feed.query('status == \"last_week\"').groupby('status', as_index = False).mean().round()\n",
    "        return df_cube_feed_week_mean\n",
    "\n",
    "    @task()\n",
    "    def transform_message_week_mean(df_cube_message):\n",
    "        df_cube_message_week_mean = df_cube_message.query('status == \"last_week\"').groupby('status', as_index = False).mean().round()\n",
    "        return df_cube_message_week_mean\n",
    "\n",
    "\n",
    "\n",
    "    @task()\n",
    "    def load_bot_report(df_cube_feed, df_cube_message, df_cube_feed_week_mean, \\\n",
    "                        df_cube_message_week_mean, df_cube_feed_stickiness, df_cube_message_stickiness):\n",
    "        # получаем данные за вчера для текстового отчета\n",
    "        df = df_cube_feed[df_cube_feed.event_date == max(df_cube_feed.event_date) - timedelta(days=1)]\n",
    "        df1 = df_cube_message[df_cube_message.event_date == max(df_cube_message.event_date) - timedelta(days=1)]\n",
    "        #отнимаю -1 день, тк  в датафрейме выводиа и сегодняшний день, иначе на графике не отображалась точка, если только данные за 1 день\n",
    "\n",
    "    # ВАРИАНТ 1   #df= df_cube_feed.iloc[-1] \n",
    "    #df_feed['event_date'].dt.strftime(\"%d.%m.%Y\") - для Series если с max(date)\n",
    "    #df_feed['event_date'].strftime(\"%d.%m.%Y\") - если .iloc[-1]\n",
    "\n",
    "\n",
    "    # отправляем текстовое сообщение #\\n - для переноса строки\n",
    "\n",
    "        msg = \"Отчет за: \" + df.event_date.dt.strftime(\"%d.%m.%Y\").values[0] +\\\n",
    "                \"\\n\\nЛента новостей\"+\\\n",
    "                \"\\nDAU: \" + str(df.dau_feed.values[0]) + \" (\"+ str(df_cube_feed_week_mean.dau_feed.values[0]) +\")\" +\\\n",
    "                \"\\nLikes: \" + str(df.likes.values[0]) + \" (\"+ str(df_cube_feed_week_mean.likes.values[0]) +\")\" +\\\n",
    "                \"\\nViews: \" + str(df.views.values[0]) + \" (\"+ str(df_cube_feed_week_mean.views.values[0]) +\")\" +\\\n",
    "                \"\\nCTR: \" + str(df.ctr.values[0]) + \"%\"+\" (\"+ str(df_cube_feed_week_mean.ctr.values[0]) + \"%\" +\")\" +\\\n",
    "                \"\\n\\nМессенджер\"+\\\n",
    "                \"\\nDAU: \" + str(df1.dau_message.values[0]) + \" (\"+ str(df_cube_message_week_mean.dau_message.values[0]) +\")\"+\\\n",
    "                \"\\nSent message: \" + str(df1.sent_message.values[0])+\" (\"+str(df_cube_message_week_mean.sent_message.values[0]) +\")\" +\\\n",
    "                \"\\n\\n(***в скобках средние значения метрик за прошлую неделю)\"            \n",
    "        \n",
    "    # отправляю графики\n",
    "\n",
    "        # Пользователи по источникам трафика\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(10, 10))         # задаю размеры\n",
    "        plt.subplots_adjust(wspace=0, hspace=0.3)\n",
    "        fig.suptitle(\"DAU ленты и мессендежра\")         # общее название графиков\n",
    "\n",
    "        axes[0].set(title='DAU ленты')\n",
    "        axes[0].set(xlabel = ' ', ylabel='DAU') \n",
    "        sns.lineplot(data=df_cube_feed, ax=axes[0], x='week_day', y='dau_feed', hue = 'status', style='status')\n",
    "\n",
    "        axes[1].set(title='DAU мессенджера ')\n",
    "        axes[1].set(xlabel = ' ', ylabel='DAU') \n",
    "        sns.lineplot(data=df_cube_message, ax=axes[1], x='week_day', y='dau_message', hue = 'status', style='status')\n",
    "\n",
    "        # сохраняю график в буфере\n",
    "        plot_object_0 = io.BytesIO()\n",
    "        fig.savefig(plot_object_0)\n",
    "        plot_object_0.seek(0) # перенос курсора в начало\n",
    "        plot_object_0.name = 'DAU_metrics.png'\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "        # Ключевые метрики за последние 7 дней\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(11, 20))         # задаю размеры\n",
    "        plt.subplots_adjust(wspace=0, hspace=0.3)\n",
    "        fig.suptitle(\"Ключевые метрики за последние 7 дней\")         # общее название графиков\n",
    "\n",
    "        axes[0].set(title='Likes')\n",
    "        axes[0].set(xlabel = ' ', ylabel='likes') \n",
    "        sns.lineplot(data=df_cube_feed, ax=axes[0], x='week_day', y='likes', hue = 'status', style='status')\n",
    "\n",
    "        axes[1].set(title='Views')\n",
    "        axes[1].set(xlabel = ' ', ylabel='views') \n",
    "        sns.lineplot(data=df_cube_feed, ax=axes[1], x='week_day', y='views', hue = 'status', style='status')\n",
    "\n",
    "        axes[2].set(title='Sent message')\n",
    "        axes[2].set(xlabel = ' ', ylabel='message') \n",
    "        sns.lineplot(data=df_cube_message, ax=axes[2], x='week_day', y='sent_message', hue = 'status', style='status')\n",
    "\n",
    "       # сохраняю график в буфере\n",
    "        plot_object_1 = io.BytesIO()\n",
    "        fig.savefig(plot_object_1)\n",
    "        plot_object_1.seek(0) # перенос курсора в начало\n",
    "        plot_object_1.name = 'Metrics.png'\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "\n",
    "    #stickiness ленты и мессенджера\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(20, 15))         # задаю размеры\n",
    "        plt.subplots_adjust(wspace=0, hspace=0.3)\n",
    "        fig.suptitle(\"stickiness ленты и мессенджера\")         # общее название графиков\n",
    "\n",
    "        axes[0].set(title='stickiness ленты')\n",
    "        axes[0].set(xlabel = ' ', ylabel='stickiness') \n",
    "        \n",
    "        sns.lineplot(data=df_cube_feed_stickiness, ax=axes[0], x='event_date', y='stickiness')\n",
    "        #plt.xticks(rotation=45)\n",
    "        #plt.xticks получает или задает свойства расположения галочек и меток оси x.\n",
    "        #rotation - это угол поворота против часовой стрелки текста этикетки оси х.\n",
    "\n",
    "        axes[1].set(title='stickiness мессенджера')\n",
    "        axes[1].set(xlabel = ' ', ylabel='stickiness') \n",
    "        sns.lineplot(data=df_cube_message_stickiness, ax=axes[1], x='event_date', y='stickiness')\n",
    "\n",
    "    # сохраняю график в буфере\n",
    "        plot_object_2 = io.BytesIO()\n",
    "        fig.savefig(plot_object_2)\n",
    "        plot_object_2.seek(0) # перенос курсора в начало\n",
    "        plot_object_2.name = 'stickiness.png'\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        # отправляю сообщение и графики\n",
    "        bot.sendMessage(chat_id=chat_id, text=msg)\n",
    "        bot.sendPhoto(chat_id=chat_id, photo=plot_object_0)\n",
    "        bot.sendPhoto(chat_id=chat_id, photo=plot_object_1)\n",
    "        bot.sendPhoto(chat_id=chat_id, photo=plot_object_2)\n",
    "\n",
    "        \n",
    "\n",
    "    @task()\n",
    "    def load_bot_picture_relplot(df_cube_feed_source, df_cube_message_source):    \n",
    "    #DAU ленты/мессенджера по источнику трафика\n",
    "        ax = sns.relplot(data=df_cube_feed_source, \n",
    "                kind='line',\n",
    "                x='week_day',\n",
    "                y='dau_feed',\n",
    "                col='source',\n",
    "                #row='sex', # можно еще задавать один параметр\n",
    "                hue='status',\n",
    "                aspect=1.10,       #соотношение сторон подграфиков определить в параметре aspect      \n",
    "                ci=None,\n",
    "                facet_kws={'sharex': False})\n",
    "        \n",
    "        ax.figure.suptitle('DAU ленты по источнику трафика')    #добавить общий заголовок к повторной диаграмме\n",
    "        ax.figure.subplots_adjust(top=.8) #переместить общий заголовок немного выше, чтобы он не мешал отдельным графикам\n",
    "        \n",
    "    # сохраняю график в буфере\n",
    "        plot_object_4 = io.BytesIO()\n",
    "        ax.figure.savefig(plot_object_4)\n",
    "        plot_object_4.seek(0) # перенос курсора в начало\n",
    "        plot_object_4.name = 'DAU_source_1.png'\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "        ax1 = sns.relplot(data=df_cube_message_source,\n",
    "                kind='line',\n",
    "                x='week_day',\n",
    "                y='dau_message',\n",
    "                col='source',\n",
    "                hue='status',\n",
    "                aspect=1.10, \n",
    "                ci=None,\n",
    "                facet_kws={'sharex': False})\n",
    "        ax1.figure.suptitle('DAU мессенджера по источнику трафика')    #добавить общий заголовок к повторной диаграмме\n",
    "        ax1.figure.subplots_adjust(top=.8) #переместить общий заголовок немного выше, чтобы он не мешал отдельным графикам\n",
    "\n",
    "    # сохраняю график в буфере\n",
    "        plot_object_5 = io.BytesIO()\n",
    "        ax1.figure.savefig(plot_object_5)\n",
    "        plot_object_5.seek(0) # перенос курсора в начало\n",
    "        plot_object_5.name = 'DAU_source_1.png'\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    # отправляю графики\n",
    "        bot.sendPhoto(chat_id=chat_id, photo=plot_object_4)\n",
    "        bot.sendPhoto(chat_id=chat_id, photo=plot_object_5)\n",
    "        \n",
    "\n",
    "        \n",
    "    #запускаю task    \n",
    "    \n",
    "    df_cube_feed = extract_feed()\n",
    "    df_cube_message = extract_message()\n",
    "\n",
    "    df_cube_feed_source = extract_feed_source()\n",
    "    df_cube_message_source = extract_message_source()\n",
    "\n",
    "    df_cube_feed_stickiness = extract_feed_stickiness()\n",
    "    df_cube_message_stickiness = extract_message_stickiness()\n",
    "\n",
    "    df_cube_feed_week_mean = transform_feed_week_mean(df_cube_feed)\n",
    "    df_cube_message_week_mean = transform_message_week_mean(df_cube_message)\n",
    "    \n",
    "    load_bot_report(df_cube_feed, df_cube_message, df_cube_feed_week_mean, df_cube_message_week_mean, \\\n",
    "                    df_cube_feed_stickiness, df_cube_message_stickiness)\n",
    "    load_bot_picture_relplot(df_cube_feed_source, df_cube_message_source)\n",
    "          \n",
    "        \n",
    "        \n",
    "aksakal_my_bot_112022 = aksakal_my_bot_112022()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
