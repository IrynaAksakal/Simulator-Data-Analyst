{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2235b6f1",
   "metadata": {},
   "source": [
    "#### ETL задачa: ожидается, что на выходе будет DAG в airflow, который будет считаться каждый день за вчера. \n",
    "\n",
    "1. Параллельно будем обрабатывать две таблицы. В feed_actions для каждого юзера посчитаем число просмотров и лайков контента. В message_actions для каждого юзера считаем, сколько он получает и отсылает сообщений, скольким людям он пишет, сколько людей пишут ему. Каждая выгрузка должна быть в отдельном таске.\n",
    "2. Далее объединяем две таблицы в одну.\n",
    "3. Для этой таблицы считаем все эти метрики в разрезе по полу, возрасту и ос. Делаем три разных таска на каждый срез.\n",
    "4. И финальные данные со всеми метриками записываем в отдельную таблицу в ClickHouse.\n",
    "5. Каждый день таблица должна дополняться новыми данными. \n",
    "\n",
    "\n",
    "##### Структура финальной таблицы должна быть такая:\n",
    "\n",
    "Дата - event_date<br>\n",
    "Название среза - dimension<br>\n",
    "Значение среза - dimension_value<br>\n",
    "Число просмотров - views<br>\n",
    "Числой лайков - likes<br>\n",
    "Число полученных сообщений - messages_received<br>\n",
    "Число отправленных сообщений - messages_sent<br>\n",
    "От скольких пользователей получили сообщения - users_received<br>\n",
    "Скольким пользователям отправили сообщение - users_sent<br>\n",
    "Срез - это os, gender и age<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e43df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import pandahouse as ph\n",
    "\n",
    "from airflow.decorators import dag, task\n",
    "#from airflow.operators.python import get_current_contex\n",
    "\n",
    "\n",
    "#для подключения к clickhouse\n",
    "connection = {'host':'https://clickhouse.lab.karpov.courses',\n",
    "              'database':'simulator_20221020',\n",
    "              'user':'student', \n",
    "              'password':'dpo_python_2020'}\n",
    "\n",
    "#для подключения к тестовой базе данных в CH\n",
    "connection_test = {'host':'https://clickhouse.lab.karpov.courses', \n",
    "              'user':'student', \n",
    "              'password':'password',\n",
    "              'database': 'test'}\n",
    "\n",
    "\n",
    "# Дефолтные параметры, которые прокидываются в таски\n",
    "default_args = {\n",
    "    'owner': 'aksakal',\n",
    "    'depends_on_past': False,\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    'start_date': datetime(2022, 9, 1), # старт дата, с которой собираем данные 01/09/2022\n",
    "    }\n",
    "\n",
    "# Интервал запуска DAG\n",
    "schedule_interval = '0 9 * * *'\n",
    "\n",
    "\n",
    "# создаем DAG \n",
    "# параметр catchup - чтобы Dag считался только за текущий день, а не за прошлые\n",
    "@dag(default_args=default_args, schedule_interval=schedule_interval, catchup=False)\n",
    "def dag_aksakal():\n",
    "\n",
    "\n",
    "    #1.1. В feed_actions для каждого юзера посчитаем число просмотров и лайков контента\n",
    "    @task()\n",
    "    def extract_feed():\n",
    "        query  = \"\"\"SELECT \n",
    "                       user_id, \n",
    "                       toDate(time) as event_date, \n",
    "                       os, \n",
    "                       IF(gender = 0, 'male', 'female') as gender,\n",
    "                       sum(action = 'like') as likes, \n",
    "                       sum(action = 'view') as views, \n",
    "                       multiIf(age <= 20, '0 - 20', \n",
    "                       age > 20 and age <= 30, '21-30', \n",
    "                       age > 30 and age <= 40, '31-40', \n",
    "                       age > 40 and age <= 50, '41-50', '50+') as age\n",
    "                   FROM \n",
    "                       {db}.feed_actions \n",
    "                        \n",
    "                   WHERE \n",
    "                       toDate(time) = today() - 1\n",
    "                   group by\n",
    "                        user_id,\n",
    "                        event_date,\n",
    "                        os, \n",
    "                        age, \n",
    "                        gender\"\"\"\n",
    "        df_cube_feed = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_feed\n",
    "        \n",
    "#1.2.В message_actions для каждого юзера считаем,сколько получает и отсылает сообщений,скольким людям пишет,сколько пишут ему \n",
    "#Число полученных сообщений - messages_received\n",
    "#Число отправленных сообщений - messages_sent\n",
    "#От скольких пользователей получили сообщения - users_received\n",
    "#Скольким пользователям отправили сообщение - users_sent\n",
    "# WHERE toDate(time) = today() - 1 -- за вчера   \n",
    "\n",
    "\n",
    "    @task()\n",
    "    def extract_message():\n",
    "        query  = '''SELECT \n",
    "                    id as user_id, \n",
    "                    event_date,\n",
    "                    messages_sent, \n",
    "                    messages_received, \n",
    "                    users_received,\n",
    "                    users_sent,\n",
    "                    os, gender, age\n",
    "                    \n",
    "                FROM\n",
    "                \n",
    "                    (SELECT user_id as id, os, \n",
    "                    toDate(time) as event_date,\n",
    "                    count(user_id) as messages_sent,\n",
    "                    countdistinct(reciever_id) as users_sent,\n",
    "                    \n",
    "                    IF(gender = 0, 'male', 'female') as gender,\n",
    "                    \n",
    "                    multiIf(age <= 20, '0 - 20', \n",
    "                    age > 20 and age <= 30, '21-30', \n",
    "                    age > 30 and age <= 40, '31-40', \n",
    "                    age > 40 and age <= 50, '41-50', '50+') as age\n",
    "                    \n",
    "                    FROM  {db}.message_actions\n",
    "                    WHERE toDate(time) = today() - 1 \n",
    "                    group by user_id, event_date, \n",
    "                    os, age, gender) t1               \n",
    "               JOIN\n",
    "                    (SELECT reciever_id as id,\n",
    "                    toDate(time) as event_date,\n",
    "                    count(reciever_id) as messages_received, \n",
    "                    countdistinct(user_id) as users_received \n",
    "                    FROM  {db}.message_actions\n",
    "                    WHERE toDate(time) = today() - 1 \n",
    "                    group by reciever_id, event_date) t2\n",
    "                USING id'''\n",
    "        df_cube_message = ph.read_clickhouse(query, connection=connection)\n",
    "        return df_cube_message\n",
    "      \n",
    "\n",
    "#2. Далее объединяем две таблицы в одну.\n",
    "    @task\n",
    "    def merge_feed_message(df_cube_feed, df_cube_message):\n",
    "        df_cube = df_cube_feed.merge(df_cube_message, on=['user_id', 'event_date', 'gender', 'age', 'os'], how='outer')\n",
    "        return df_cube\n",
    "\n",
    "                    \n",
    "#3. Для этой таблицы считаем все эти метрики в разрезе по полу, возрасту и ос. Делаем три разных таска на каждый срез.   \n",
    "    @task\n",
    "    def transform_age(df_cube):\n",
    "        df_cube_age = df_cube[['event_date', 'age','likes', 'views', 'messages_sent', 'messages_received', \\\n",
    "                      'users_received', 'users_sent']].groupby(['age', 'event_date']).sum().reset_index()\n",
    "        df_cube_age ['dimension'] = 'age'\n",
    "        df_cube_age .rename(columns= {'age': 'dimension_value'}, inplace=True)\n",
    "        return  df_cube_age \n",
    "\n",
    "    @task\n",
    "    def transform_gender(df_cube):\n",
    "        df_cube_gender = df_cube[['event_date', 'gender','likes', 'views', 'messages_sent', 'messages_received', \\\n",
    "                      'users_received', 'users_sent']].groupby(['gender','event_date']).sum().reset_index()\n",
    "        df_cube_gender['dimension'] = 'gender'\n",
    "        df_cube_gender.rename(columns= {'gender': 'dimension_value'}, inplace=True)\n",
    "        return df_cube_gender\n",
    "\n",
    "    @task\n",
    "    def transform_os(df_cube):\n",
    "        df_cube_os = df_cube[['event_date', 'os','likes', 'views', 'messages_sent', 'messages_received', \\\n",
    "                      'users_received', 'users_sent']].groupby(['os', 'event_date']).sum().reset_index()\n",
    "        df_cube_os['dimension'] = 'os'\n",
    "        df_cube_os.rename(columns= {'os': 'dimension_value'}, inplace=True)\n",
    "        return df_cube_os\n",
    "  \n",
    "    # объединяю финальные данные со всеми метриками\n",
    "    @task\n",
    "    def concat_metrics_table(df_cube_age, df_cube_gender, df_cube_os):\n",
    "        metrics_table = pd.concat([df_cube_age, df_cube_gender, df_cube_os]).reset_index(drop=True)\n",
    "       \n",
    "        # изменила типы данных - подготовка к записи в базу test\n",
    "        metrics_table = metrics_table.astype({'dimension': str, 'dimension_value': str,'likes':  int, 'views':  int,\\\n",
    "                        'messages_sent':  int, 'messages_received': int, 'users_received': int, 'users_sent':  int}) \n",
    "        metrics_table['event_date'] = pd.to_datetime(metrics_table['event_date']) # изменила тип на дата\n",
    "        return metrics_table\n",
    "    \n",
    "    \n",
    "#4. И финальные данные со всеми метриками записываем в отдельную таблицу в ClickHouse.   \n",
    "    @task\n",
    "    def load(metrics_table):  \n",
    "        #подключаемся к тестовой базе данных\n",
    "        q_create = ('''CREATE TABLE IF NOT EXISTS test.aksakal_table\n",
    "                  (event_date Date,\n",
    "                  dimension VARCHAR(255),\n",
    "                  dimension_value VARCHAR(255),\n",
    "                  views Int64,\n",
    "                  likes Int64,\n",
    "                  messages_received Int64,\n",
    "                  messages_sent Int64,\n",
    "                  users_received Int64,\n",
    "                  users_sent Int64)\n",
    "                  ENGINE = MergeTree()\n",
    "                  ORDER BY event_date''')\n",
    "    \n",
    "        ph.execute(query=q_create, connection=connection_test)\n",
    "        ph.to_clickhouse(df=metrics_table, table='aksakal_table', connection=connection_test, index=False)\n",
    "                                          \n",
    "                                                  \n",
    "    #запускаем task   \n",
    "    df_cube_feed =  extract_feed()\n",
    "    df_cube_message = extract_message()\n",
    "    df_cube = merge_feed_message(df_cube_feed, df_cube_message)\n",
    "    df_cube_age = transform_age(df_cube)\n",
    "    df_cube_gender = transform_gender(df_cube)\n",
    "    df_cube_os = transform_os(df_cube)\n",
    "    metrics_table = concat_metrics_table(df_cube_age, df_cube_gender, df_cube_os)\n",
    "    load(metrics_table)\n",
    "\n",
    "    \n",
    "# запускаем dag  \n",
    "dag_aksakal = dag_aksakal()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
